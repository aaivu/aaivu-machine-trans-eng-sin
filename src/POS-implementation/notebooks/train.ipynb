{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pTLDQvv4Xg1"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgQHwOzKYH3e"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-asBuk14dpu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N9IQ2i6uVdz"
      },
      "source": [
        "#Install fairseq\r\n",
        "import os\r\n",
        "\r\n",
        "# If POS integration with input embedding\r\n",
        "os.chdir('.........../POS-implementation/fairseq/Fairseq-POS-integration-input-embedding')\r\n",
        "\r\n",
        "# If POS integration with positional encoding\r\n",
        "os.chdir('.........../POS-implementation/fairseq/Fairseq-POS-integration-positional-encoding')\r\n",
        "\r\n",
        "!pip install --editable .\r\n",
        "!pip install sentencepiece sacrebleu tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiWJdkQvudkt"
      },
      "source": [
        "import os\r\n",
        "os.chdir('...........src/Subword-segmentation/Transformer-BPE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLQcbUEIraYM"
      },
      "source": [
        "# Preprocess the data\n",
        "os.chdir('............../scripts')\n",
        "!bash preprocess-joined-ensi.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OudSUfqp4sSF"
      },
      "source": [
        "import os  \n",
        "os.chdir(\"............./Transformer-BPE\")\n",
        "!CUDA_VISIBLE_DEVICES=0 fairseq-train \\\n",
        "    data-bin/en_si_bpe5000/ \\\n",
        "    --source-lang en --target-lang si \\\n",
        "    --arch transformer \\\n",
        "    --encoder-layers 5 --decoder-layers 5 \\\n",
        "    --encoder-num-pos 42 \\\n",
        "    --encoder-pos-embed-dim 16 \\\n",
        "    --combine-bpe-path 'path to combine.bpe.en file' \\\n",
        "    --combine-numbers-path 'path to combine.numbers.en file' \\\n",
        "    --encoder-embed-dim 512 --decoder-embed-dim 512 \\\n",
        "    --encoder-normalize-before --decoder-normalize-before \\\n",
        "    --encoder-ffn-embed-dim 2048 --decoder-ffn-embed-dim 2048 \\\n",
        "    --encoder-attention-heads 2 --decoder-attention-heads 2 \\\n",
        "    --dropout 0.4 --attention-dropout 0.2 --relu-dropout 0.2 \\\n",
        "    --weight-decay 0.0001 \\\n",
        "    --label-smoothing 0.2 --criterion label_smoothed_cross_entropy \\\n",
        "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0 \\\n",
        "    --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-7 \\\n",
        "    --lr 1e-3 --min-lr 1e-9 \\\n",
        "    --batch-size 32 \\\n",
        "    --update-freq 4 \\\n",
        "    --max-epoch 200 --save-interval 10 \\\n",
        "    --tensorboard-logdir logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ismcFwIm4w8G"
      },
      "source": [
        "#200 epoch - validation set\n",
        "# Obtain the BLEU score for validation dataset\n",
        "!fairseq-generate \\\n",
        "    data-bin/en_si_bpe5000/ \\\n",
        "    --source-lang en --target-lang si \\\n",
        "    --path checkpoints/checkpoint_best.pt \\\n",
        "    --beam 5 --lenpen 1.2 \\\n",
        "    --gen-subset valid \\\n",
        "    --remove-bpe=sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f5OccMA8HJw"
      },
      "source": [
        "#200 epoch - test set\n",
        "# Obtain the BLEU score for test dataset\n",
        "!fairseq-generate \\\n",
        "    data-bin/en_si_bpe5000/ \\\n",
        "    --source-lang en --target-lang si \\\n",
        "    --path checkpoints/checkpoint_best.pt \\\n",
        "    --beam 5 --lenpen 1.2 \\\n",
        "    --gen-subset test \\\n",
        "    --remove-bpe=sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6WIEq9xvAGs"
      },
      "source": [
        "# Obtain the checkpoint ensemble BLEU score for validation dataset\r\n",
        "!fairseq-generate \\\r\n",
        "    data-bin/en_si_bpe5000/ \\\r\n",
        "    --source-lang en --target-lang si \\\r\n",
        "    --path checkpoints/checkpoint_last.pt:checkpoints/checkpoint190.pt \\\r\n",
        "    --beam 5 --lenpen 1.2 \\\r\n",
        "    --gen-subset valid \\\r\n",
        "    --remove-bpe=sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wImoh8livByQ"
      },
      "source": [
        "# Obtain the checkpoint ensembled BLEU score for test dataset\r\n",
        "!fairseq-generate \\\r\n",
        "    data-bin/en_si_bpe5000/ \\\r\n",
        "    --source-lang en --target-lang si \\\r\n",
        "    --path checkpoints/checkpoint_last.pt:checkpoints/checkpoint190.pt \\\r\n",
        "    --beam 5 --lenpen 1.2 \\\r\n",
        "    --gen-subset test \\\r\n",
        "    --remove-bpe=sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVBSjp8KvDWv"
      },
      "source": [
        "# Load the TensorBoard notebook extension\r\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgECIWqHvFPk"
      },
      "source": [
        "# Visualize using tensorboard\r\n",
        "%tensorboard --logdir logs/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}